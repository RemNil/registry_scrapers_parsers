{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is not a simple way to get the current max trial ID via code.\n",
    "#This needs to be retrieved manually by:\n",
    "#Visting the CTRI\n",
    "#Doing the broadest possible search (i.e. searching for the letter 'a')\n",
    "#Waiting for the results to load and manually retireving the URL of the last record on the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests import ConnectionError\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import csv\n",
    "from time import sleep\n",
    "\n",
    "try:\n",
    "    get_ipython\n",
    "    from tqdm.notebook import tqdm\n",
    "except NameError:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    tries=3\n",
    "    for i in range(tries):\n",
    "        try:\n",
    "            response = get(url, verify = False, headers=headers)\n",
    "        except ConnectionError as e:\n",
    "            if i < tries - 1:\n",
    "                sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def get_tables(html): #It's too unpredictable which tables can be missing from a record. This probably needs\n",
    "    #Some kind of validation by the text in the table to what should be in the table\n",
    "    #For instance this http://ctri.nic.in/Clinicaltrials/pmaindet2.php?trialid=788 breaks our fix for trial 184\n",
    "    tables = html.find_all('table')\n",
    "    table_names = [\n",
    "        'all',\n",
    "        'header',\n",
    "        'cont1',\n",
    "        'ids',\n",
    "        'pi',\n",
    "        'sci_con',\n",
    "        'pub_con',\n",
    "        'mon_sup',\n",
    "        'p_spon',\n",
    "        's_spon',\n",
    "        'sites',\n",
    "        'ethics',\n",
    "        'reg',\n",
    "        'conds',\n",
    "        'ints',\n",
    "        'inc_c',\n",
    "        'ex_c',\n",
    "        'p_out',\n",
    "        's_out'\n",
    "    ]\n",
    "    if len(tables) == len(table_names):\n",
    "        table_dict = dict(zip(table_names,tables))\n",
    "    elif len(tables) < len(table_names) and len(tables) > 0:\n",
    "        #for now it seems like ids is the only table that can be missing\n",
    "        #for example http://ctri.nic.in/Clinicaltrials/pmaindet2.php?trialid=184\n",
    "        table_names.remove('ids')\n",
    "        table_dict = dict(zip(table_names, tables))\n",
    "    elif len(tables) > len(table_names):\n",
    "        #this deals with when an extra table is thrown in within the results section\n",
    "        #here: http://ctri.nic.in/Clinicaltrials/pmaindet2.php?trialid=719\n",
    "        tables = tables[0:-1]\n",
    "        table_dict = dict(zip(table_names, tables))\n",
    "    else:\n",
    "        return None\n",
    "    return table_dict\n",
    "\n",
    "headers = [\n",
    "    'ctri_number',\n",
    "    'registration_date',\n",
    "    'registration_type',\n",
    "    'last_modified',\n",
    "    'post_grad_thesis',\n",
    "    'type_of_trial',\n",
    "    'type_of_study',\n",
    "    'study_design',\n",
    "    'public_title_of_study',\n",
    "    'scientific_title_of_study',\n",
    "    'secondary_id',\n",
    "    'pi_info',\n",
    "    'scientific_contact',\n",
    "    'public_contact',\n",
    "    'sources_of_monetary_or_material_support',\n",
    "    'primary_sponsor',\n",
    "    'secondary_sponsor',\n",
    "    'recruitment_countries',\n",
    "    'number_of_sites',\n",
    "    'study_sites',\n",
    "    'ethics_details',\n",
    "    'dcgi_reg_status',\n",
    "    'conditions_studied',\n",
    "    'intervention',\n",
    "    'inclusion_criteria',\n",
    "    'exclusion_criteria',\n",
    "    'method_rand_seq',\n",
    "    'concealment_method',\n",
    "    'blinding_masking',\n",
    "    'primary_outcomes',\n",
    "    'secondary_outcomes',\n",
    "    'target_sample_size',\n",
    "    'phase',\n",
    "    'date_of_first_enrollment_india',\n",
    "    'date_of_study_completion_india',\n",
    "    'date_of_first_enrollment_global',\n",
    "    'date_of_study_completion_global',\n",
    "    'estimated_duration',\n",
    "    'recruitment_status_global',\n",
    "    'recruitment_status_india',\n",
    "    'publication_details',\n",
    "    'brief_summary'\n",
    "]\n",
    "\n",
    "def get_changes(page, blid):\n",
    "    change_dates = []\n",
    "    change_log = get_url('http://ctri.nic.in/Clinicaltrials/pviewmod.php?trialid={}&blid={}&EncHid=&modid=&compid='.format(page, blid))\n",
    "    changes = change_log.find_all('td', text=re.compile('^\\d{2}/\\d{2}/\\d{4}$'))\n",
    "    if changes:\n",
    "        for c in changes:\n",
    "            change_dates.append(c.text)\n",
    "        return change_dates\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_date = re.compile(r'\\d{2}/\\d{2}/\\d{4}\\b')\n",
    "digits = re.compile(r'\\b\\d{1,3}\\b')\n",
    "\n",
    "def strip_chars(text):\n",
    "    return text.replace('\\t',' ').replace('\\n',' ').replace('\\r',' ').replace('\\xa0',' ')\n",
    "\n",
    "def reg_type():\n",
    "    c_font = trial_info['cont1'].find_all('font')[0].get_text()\n",
    "    if 'Trial Registered' in c_font:\n",
    "        return c_font\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def text_strip(table, index):\n",
    "    tds = trial_info[table].find_all('td')\n",
    "    return strip_chars(tds[index].text.strip())\n",
    "\n",
    "def tables(cols, column_names, tab_name, extra_row = False):\n",
    "    counter = 0\n",
    "    table_contents = []\n",
    "    t = trial_info[tab_name].find_all('td')\n",
    "    tab_values = list(range(cols,len(t)))\n",
    "    rows = list(range(cols,len(t),cols))\n",
    "    if extra_row:\n",
    "        tab_values = list(range(cols+1,len(t)))\n",
    "        rows = list(range(cols+1,len(t),cols))\n",
    "    counter = 0\n",
    "    for row in rows:\n",
    "        d = {}\n",
    "        for name, v in zip(column_names, tab_values[counter:row]):\n",
    "            if t[v].text.strip() == 'NIL' or t[v].text.strip() == None:\n",
    "                d[name] = None\n",
    "            else:\n",
    "                d[name] = strip_chars(t[v].text.strip())\n",
    "        counter += cols\n",
    "        table_contents.append(d)                \n",
    "    if len(table_contents) == 1 and (not all(table_contents[0].values())):\n",
    "        return(None)\n",
    "    elif len(table_contents) == 1 and (all(table_contents[0].values())):\n",
    "        return(table_contents[0])\n",
    "    elif len(table_contents) > 1:\n",
    "        return(table_contents)\n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "def bare_table(table):\n",
    "    contact_info = {}\n",
    "    for tr in trial_info[table].find_all('tr'):\n",
    "        key = tr.find_all('td')[0].text.strip()\n",
    "        value = strip_chars(tr.find_all('td')[1].text.strip())\n",
    "        contact_info[key.replace(' ','_').lower()] = value\n",
    "    if not all(contact_info.values()):\n",
    "        return None\n",
    "    else:\n",
    "        return contact_info\n",
    "\n",
    "def countries():\n",
    "    tds = trial_info['cont1'].find_all('td')\n",
    "    index = -1\n",
    "    for td in tds:\n",
    "        index += 1\n",
    "        if td.find(text='Countries of Recruitment'):\n",
    "            i = index\n",
    "            break\n",
    "    locs = list(tds[i+1].stripped_strings)\n",
    "    if len(locs) == 1:\n",
    "        return locs[0]\n",
    "    else:\n",
    "        return locs\n",
    "\n",
    "def bare_text(field, table, find_index=False):\n",
    "    tds = trial_info[table].find_all('td')\n",
    "    index = -1\n",
    "    for td in tds:\n",
    "        index += 1\n",
    "        if td.find(text = field):\n",
    "            i = index\n",
    "            break\n",
    "    if find_index:\n",
    "        return i\n",
    "    elif not find_index:\n",
    "        return strip_chars(tds[i+1].text.strip())\n",
    "    \n",
    "def list_of_fields(td, v_type=str):\n",
    "    els = list(td.stripped_strings)\n",
    "    clean_els = []\n",
    "    for el in els:\n",
    "        stripped = strip_chars(el.strip().replace('=','').replace('\"','').replace(' ','_').lower())\n",
    "        clean_els.append(stripped)\n",
    "    key_i = list(range(0,len(els),2))\n",
    "    fdict = {}\n",
    "    for i in key_i:\n",
    "        if clean_els[i+1] == '':\n",
    "            fdict[clean_els[i]] = None\n",
    "        else:\n",
    "            fdict[clean_els[i]] = v_type(clean_els[i+1])\n",
    "    return fdict\n",
    "\n",
    "def make_date(date):\n",
    "    if date == \"Date Missing\" or date == '00/00/0000' or not date:\n",
    "        return None\n",
    "    elif 'Applicable only for' in date:\n",
    "        return 'Not Applicable'\n",
    "    else:\n",
    "        return datetime.strptime(date,'%d/%m/%Y').date()\n",
    "    \n",
    "def myconverter(o):\n",
    "    if isinstance(o, date):\n",
    "        return o.__str__()\n",
    "\n",
    "#This is an attempt at scraping every field on the registry. It currently is not 100% functional across all fields.\n",
    "#Below we make a new function that shortens this to only what is needed for our project on registry results.\n",
    "#Can come back to in the future and try and fix.\n",
    "def make_dict(trial_info):\n",
    "    trial_dict = {}\n",
    "    trial_dict['ctri_number'] = trial_info['cont1'].find_all('b')[1].text.strip()\n",
    "    trial_dict['registration_date'] = reg_date.findall(str(trial_info['cont1']))[0]\n",
    "    trial_dict['registration_type'] = reg_type()\n",
    "    trial_dict['last_modified'] = text_strip('cont1',3)\n",
    "    trial_dict['post_grad_thesis'] = text_strip('cont1',5)\n",
    "    trial_dict['type_of_trial'] = text_strip('cont1',7) \n",
    "    trial_dict['type_of_study'] = text_strip('cont1',9) \n",
    "    trial_dict['study_design'] = text_strip('cont1',11) \n",
    "    trial_dict['public_title_of_study'] = text_strip('cont1',13) \n",
    "    trial_dict['scientific_title_of_study'] = text_strip('cont1',15)\n",
    "    if 'id' in trial_info:\n",
    "        id_names = ['id', 'identifier_type']\n",
    "        trial_dict['secondary_id'] = tables(2, id_names, 'ids')\n",
    "    trial_dict['pi_info'] = bare_table('pi')\n",
    "    trial_dict['scientific_contact'] = bare_table('sci_con')\n",
    "    trial_dict['public_contact'] = bare_table('pub_con')\n",
    "    trial_dict['sources_of_monetary_or_material_support'] = text_strip('mon_sup', 0)\n",
    "    trial_dict['primary_sponsor'] = bare_table('p_spon')\n",
    "    spon_cols = ['name', 'address']\n",
    "    trial_dict['secondary_sponsor'] = tables(2, spon_cols, 's_spon')\n",
    "    trial_dict['recruitment_countries'] = countries()\n",
    "    trial_dict['number_of_sites'] = int(digits.findall(trial_info['sites'].td.text.strip())[0])\n",
    "    sites_cols = ['pi', 'site_name', 'site_address', 'site_contact']\n",
    "    trial_dict['study_sites'] = tables(4,sites_cols,'sites',extra_row = True)\n",
    "    ethics_cols = ['committee', 'status']\n",
    "    trial_dict['ethics_details'] = tables(2,ethics_cols,'ethics',extra_row = True)\n",
    "    trial_dict['dcgi_reg_status'] = trial_info['reg'].find_all('td')[1].text.strip()\n",
    "    cond_cols = ['health_type','conditions']\n",
    "    trial_dict['conditions_studied'] = tables(2,cond_cols,'conds')\n",
    "    int_cols = ['type', 'name', 'details']\n",
    "    trial_dict['intervention'] = tables(3, int_cols, 'ints')\n",
    "    trial_dict['inclusion_criteria'] = bare_table('inc_c')\n",
    "    trial_dict['exclusion_criteria'] = trial_info['ex_c'].find_all('td')[1].text.strip()\n",
    "    trial_dict['method_rand_seq'] = bare_text('Method of Generating Random Sequence', 'cont1')\n",
    "    trial_dict['concealment_method'] = bare_text('Method of Concealment', 'cont1')\n",
    "    trial_dict['blinding_masking'] = bare_text('Blinding/Masking', 'cont1')\n",
    "    outcome_cols = ['outcomes', 'timepoint']\n",
    "    trial_dict['primary_outcomes'] = tables(2,outcome_cols,'p_out')\n",
    "    trial_dict['secondary_outcomes'] = tables(2,outcome_cols,'s_out')\n",
    "    enrollment = trial_info['cont1'].find_all('td')[-1]\n",
    "    trial_dict['target_sample_size'] = list_of_fields(enrollment)\n",
    "    trial_dict['phase'] = bare_text('Phase of Trial','all')\n",
    "    trial_dict['date_of_first_enrollment_india'] = make_date(bare_text('Date of First Enrollment (India)','all'))\n",
    "    trial_dict['date_of_study_completion_india'] = make_date(bare_text('Date of Study Completion (India)','all'))\n",
    "    trial_dict['date_of_first_enrollment_global'] = make_date(bare_text('Date of First Enrollment (Global)','all'))\n",
    "    trial_dict['date_of_study_completion_global'] = make_date(bare_text('Date of Study Completion (Global)','all'))\n",
    "    duration_index = bare_text('Estimated Duration of Trial', 'all', find_index=True)\n",
    "    duration = trial_info['all'].find_all('td')[duration_index+1]\n",
    "    trial_dict['estimated_duration'] = list_of_fields(duration, v_type=int)\n",
    "    trial_dict['recruitment_status_global'] = bare_text('Recruitment Status of Trial (Global)', 'all')\n",
    "    trial_dict['recruitment_status_india'] = bare_text('Recruitment Status of Trial (India)', 'all')\n",
    "    trial_dict['publication_details'] = bare_text('Publication Details', 'all')\n",
    "    trial_dict['brief_summary'] = bare_text('Brief Summary','all')\n",
    "    return trial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = 0\n",
    "last_trial_id = 40107 #as of 25 Jan 2020\n",
    "pages = [str(i) for i in range(1,(last_trial_id+1))]\n",
    "requests = 0\n",
    "skipped = 0\n",
    "written = 0\n",
    "url = 'http://ctri.nic.in/Clinicaltrials/pmaindet2.php?trialid={}'\n",
    "pub_results_changed = []\n",
    "bsum_results_changed = []\n",
    "trials = []\n",
    "#test_pages = [str(i) for i in range(1,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only the fields we need for our current analysis\n",
    "\n",
    "def just_results(trial_info):\n",
    "    trial_dict = {}\n",
    "    trial_dict['ctri_number'] = trial_info['cont1'].find_all('b')[1].text.strip()\n",
    "    trial_dict['registration_date'] = reg_date.findall(str(trial_info['cont1']))[0]\n",
    "    trial_dict['registration_type'] = reg_type()\n",
    "    trial_dict['type_of_trial'] = text_strip('cont1',7)\n",
    "    trial_dict['public_title_of_study'] = text_strip('cont1',13)\n",
    "    trial_dict['phase'] = bare_text('Phase of Trial','all')\n",
    "    trial_dict['date_of_first_enrollment_india'] = make_date(bare_text('Date of First Enrollment (India)','all'))\n",
    "    trial_dict['date_of_study_completion_india'] = make_date(bare_text('Date of Study Completion (India)','all'))\n",
    "    trial_dict['date_of_first_enrollment_global'] = make_date(bare_text('Date of First Enrollment (Global)','all'))\n",
    "    trial_dict['date_of_study_completion_global'] = make_date(bare_text('Date of Study Completion (Global)','all'))\n",
    "    trial_dict['recruitment_status_global'] = bare_text('Recruitment Status of Trial (Global)', 'all')\n",
    "    trial_dict['recruitment_status_india'] = bare_text('Recruitment Status of Trial (India)', 'all')\n",
    "    trial_dict['publication_details'] = bare_text('Publication Details', 'all')\n",
    "    #Brief Summaries are now excluded from the scrape as they are often large and unweildy and can break the resulting CSV\n",
    "    #trial_dict['brief_summary'] = bare_text('Brief Summary','all')\n",
    "    return trial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30571485461a439794cf91fc86282a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17604.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Scraping is a bit slow moving here. You might have it break for Timeout reasons in which case you can just restart and \n",
    "#slice the pages list from where it broke. So if it broke on trial 1400, add [1400:] to the end of `pages` in `tqdm(pages)`\n",
    "#We also scrape the \"Changes\" section to the publication and brief summary fields \n",
    "#for our project\n",
    "\n",
    "for page in tqdm(pages):\n",
    "    requests += 1\n",
    "    soup = get_url(url.format(page))\n",
    "    trial_info = get_tables(soup)\n",
    "    last_td = soup.find_all('td')[-1].text\n",
    "    if 'Invalid Request!!!' in last_td:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    else:\n",
    "        t_dict = just_results(trial_info)\n",
    "        trials.append(t_dict)\n",
    "        pub_changes = get_changes(page, 29)\n",
    "        pc_dict = {}\n",
    "        if pub_changes:\n",
    "            pc_dict['ctri_number'] = t_dict['ctri_number']\n",
    "            pc_dict['pub_changes'] = pub_changes\n",
    "            pub_results_changed.append(pc_dict)\n",
    "        bsum_changes = get_changes(page, 28)\n",
    "        bc_dict = {}\n",
    "        if bsum_changes:\n",
    "            bc_dict['ctri_number'] = t_dict['ctri_number']\n",
    "            bc_dict['bsum_changes'] = bsum_changes\n",
    "            bsum_results_changed.append(bc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_headers = ['ctri_number', 'registration_date', 'registration_type', 'type_of_trial', 'public_title_of_study', \n",
    "                  'phase', 'date_of_first_enrollment_india', 'date_of_study_completion_india', \n",
    "                  'date_of_first_enrollment_global', 'date_of_study_completion_global', 'recruitment_status_global', \n",
    "                  'recruitment_status_india', 'publication_details']\n",
    "\n",
    "with open('ctri_trials_{}.csv'.format(date.today()), 'w', newline='', encoding='utf-8') as ctri_csv:\n",
    "    writer = csv.DictWriter(ctri_csv, fieldnames=simple_headers)\n",
    "    writer.writeheader()\n",
    "    for t in trials:\n",
    "        writer.writerow(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#This is me being lazy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "p_changes = pd.DataFrame(pub_results_changed)\n",
    "p_changes.to_csv('pub_results_changes_{}.csv'.format(date.today()))\n",
    "\n",
    "b_changes = pd.DataFrame(bsum_results_changed)\n",
    "b_changes.to_csv('bsum_results_changes_{}.csv'.format(date.today()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
